#!/usr/bin/env python3
"""
Convex â†’ Supabase Migration Agent
Runs in GitHub Actions to port a React Native + Convex app to Supabase.
Uses the Cursor API (Claude 3.5 Sonnet) for intelligent code transformation.
"""

import argparse
import json
import os
import re
import shutil
import sys
import time
from pathlib import Path
from typing import Generator

import requests

# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CURSOR_API_URL = "https://api.cursor.sh/v1/chat/completions"
CURSOR_MODEL = "claude-3-5-sonnet-20241022"
MAX_TOKENS = 8000
REQUEST_DELAY_SECONDS = 1.0  # Be polite to the API

IGNORE_DIRS = {
    "node_modules", ".git", ".expo", "dist", "build",
    ".next", "__pycache__", ".convex", ".cache", "android", "ios",
}
IGNORE_EXTENSIONS = {
    ".png", ".jpg", ".jpeg", ".gif", ".ico", ".ttf", ".otf",
    ".woff", ".woff2", ".mp4", ".mp3", ".zip", ".tar", ".gz",
    ".lock",  # package-lock, yarn.lock handled separately
}
CODE_EXTENSIONS = {
    ".ts", ".tsx", ".js", ".jsx", ".json", ".md",
    ".env", ".example", ".sql",
}

# â”€â”€â”€ SYSTEM PROMPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SYSTEM_PROMPT = """You are an expert React Native and backend developer specializing in migrating
applications from Convex to Supabase.

## Core Transformation Rules

### Backend (convex/ â†’ supabase/)
- Replace `convex/schema.ts` with `supabase/migrations/001_initial.sql` (CREATE TABLE statements with RLS)
- Replace Convex server functions (queries, mutations, actions) with Supabase Edge Functions where needed
- Create `supabase/config.ts` â€” Supabase client singleton using env vars
- Create `supabase/types.ts` â€” TypeScript types matching the schema

### Client-side hooks
| Convex | Supabase replacement |
|--------|---------------------|
| `useQuery(api.x.list)` | `useState` + `useEffect` with `supabase.from('x').select()`, or real-time subscription via `supabase.channel()` |
| `useMutation(api.x.create)` | async function calling `supabase.from('x').insert()` |
| `useMutation(api.x.update)` | async function calling `supabase.from('x').update()` |
| `useMutation(api.x.delete)` | async function calling `supabase.from('x').delete()` |
| `useAction(api.x.action)` | async function calling a Supabase Edge Function |
| `ConvexProvider` | wrap app with nothing special; Supabase client is a singleton |
| `ConvexAuthNextjsServerProvider` | `supabase.auth` |

### Auth
- Replace Convex auth with `supabase.auth.signUp()`, `supabase.auth.signInWithPassword()`, etc.
- For session: use `supabase.auth.getSession()` and `supabase.auth.onAuthStateChange()`

### Package changes
- Remove: `convex`, `@convex-dev/*`
- Add: `@supabase/supabase-js`
- Env vars: `EXPO_PUBLIC_SUPABASE_URL`, `EXPO_PUBLIC_SUPABASE_ANON_KEY`

## Output Format

For files to create or modify, use EXACTLY this format (no markdown code fences around it):
<FILE path="relative/path/to/file">
file content here
</FILE>

For files to delete:
<DELETE path="relative/path/to/file" />

Only output files that need to change. Skip files with no Convex references."""


# â”€â”€â”€ CURSOR API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def call_cursor_api(system: str, user: str, api_key: str, retries: int = 3) -> str:
    """Call the Cursor API with retry logic."""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "model": CURSOR_MODEL,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        "max_tokens": MAX_TOKENS,
        "temperature": 0.1,
    }

    for attempt in range(retries):
        try:
            resp = requests.post(CURSOR_API_URL, headers=headers, json=payload, timeout=120)
            resp.raise_for_status()
            data = resp.json()
            return data["choices"][0]["message"]["content"]
        except requests.exceptions.HTTPError as e:
            if resp.status_code == 429:
                wait = 10 * (attempt + 1)
                print(f"  â³ Rate limited. Waiting {wait}s...")
                time.sleep(wait)
            elif attempt < retries - 1:
                print(f"  âš ï¸  HTTP error {resp.status_code}, retrying ({attempt+1}/{retries})...")
                time.sleep(3)
            else:
                raise RuntimeError(f"Cursor API failed after {retries} attempts: {e}") from e
        except requests.exceptions.Timeout:
            if attempt < retries - 1:
                print(f"  â° Timeout, retrying ({attempt+1}/{retries})...")
                time.sleep(5)
            else:
                raise

    return ""


# â”€â”€â”€ FILE UTILITIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def iter_source_files(root: Path) -> Generator[Path, None, None]:
    """Yield all relevant source files, skipping ignored dirs/extensions."""
    for path in sorted(root.rglob("*")):
        if path.is_dir():
            continue
        # Skip ignored directories anywhere in path
        if any(part in IGNORE_DIRS for part in path.parts):
            continue
        # Skip binary/lock files
        if path.suffix in IGNORE_EXTENSIONS:
            continue
        yield path


def read_file_safe(path: Path, max_bytes: int = 80_000) -> str:
    """Read a file safely, truncating if too large."""
    try:
        size = path.stat().st_size
        if size > max_bytes:
            return f"[FILE TOO LARGE: {size} bytes, skipped]"
        return path.read_text(encoding="utf-8", errors="replace")
    except Exception as e:
        return f"[ERROR READING: {e}]"


def parse_file_blocks(response: str) -> list[dict]:
    """Parse <FILE> and <DELETE> blocks from the AI response."""
    changes = []

    # Match <FILE path="...">content</FILE>
    file_pattern = re.compile(r'<FILE\s+path="([^"]+)">(.*?)</FILE>', re.DOTALL)
    for match in file_pattern.finditer(response):
        changes.append({
            "action": "write",
            "path": match.group(1).lstrip("/"),
            "content": match.group(2).strip(),
        })

    # Match <DELETE path="..." />
    delete_pattern = re.compile(r'<DELETE\s+path="([^"]+)"\s*/>')
    for match in delete_pattern.finditer(response):
        changes.append({
            "action": "delete",
            "path": match.group(1).lstrip("/"),
            "content": "",
        })

    return changes


def uses_convex(content: str) -> bool:
    """Quick check if a file likely references Convex."""
    convex_markers = [
        "from 'convex", 'from "convex',
        "useQuery", "useMutation", "useAction",
        "ConvexProvider", "ConvexReactClient",
        "api.", "convex/",
    ]
    return any(marker in content for marker in convex_markers)


def batch(items: list, size: int) -> Generator[list, None, None]:
    """Split a list into batches of given size."""
    for i in range(0, len(items), size):
        yield items[i : i + size]


# â”€â”€â”€ MIGRATION STEPS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step_analyze(source_root: Path) -> dict:
    """Collect information about the codebase."""
    all_files = list(iter_source_files(source_root))
    convex_files = [f for f in all_files if "convex" in str(f.relative_to(source_root)).split("/")[0]]
    convex_using = [
        f for f in all_files
        if f.suffix in CODE_EXTENSIONS and uses_convex(read_file_safe(f))
    ]

    print(f"  Total source files:        {len(all_files)}")
    print(f"  convex/ backend files:     {len(convex_files)}")
    print(f"  Files that import Convex:  {len(convex_using)}")

    return {
        "all_files": all_files,
        "convex_files": convex_files,
        "convex_using": convex_using,
    }


def step_generate_schema(source_root: Path, api_key: str) -> list[dict]:
    """Generate Supabase schema, types, and client config from Convex backend files."""
    print("  Reading Convex schema + backend files...")

    convex_dir = source_root / "convex"
    if not convex_dir.exists():
        print("  âš ï¸  No convex/ directory found â€” will infer schema from app code")
        convex_content = "(No convex/ directory found)"
    else:
        parts = []
        for f in sorted(convex_dir.rglob("*.ts")):
            rel = f.relative_to(source_root)
            parts.append(f"=== {rel} ===\n{read_file_safe(f)}")
        convex_content = "\n\n".join(parts) if parts else "(convex/ is empty)"

    pkg_json = read_file_safe(source_root / "package.json")
    app_json_path = source_root / "app.json"
    app_json = read_file_safe(app_json_path) if app_json_path.exists() else ""

    prompt = f"""Analyze this Convex backend and generate the complete Supabase foundation files.

## package.json
{pkg_json}

## app.json
{app_json}

## Convex backend files
{convex_content}

Please generate ALL of the following files:
1. `supabase/migrations/001_initial.sql` â€” Full schema with CREATE TABLE, RLS policies, and indexes
2. `supabase/types.ts` â€” TypeScript types matching every table
3. `supabase/config.ts` â€” Supabase client singleton (use EXPO_PUBLIC_ prefixed env vars for Expo)
4. `.env.example` â€” Template with EXPO_PUBLIC_SUPABASE_URL and EXPO_PUBLIC_SUPABASE_ANON_KEY
5. Updated `package.json` â€” Remove convex packages, add @supabase/supabase-js"""

    print("  Calling Cursor API for schema generation...")
    response = call_cursor_api(SYSTEM_PROMPT, prompt, api_key)
    changes = parse_file_blocks(response)
    print(f"  Generated {len(changes)} schema/config files")
    return changes


def step_migrate_files(
    source_root: Path,
    convex_using: list[Path],
    context_summary: str,
    api_key: str,
) -> list[dict]:
    """Migrate each file that uses Convex, in batches."""
    all_changes = []
    file_batches = list(batch(convex_using, 5))

    for i, file_batch in enumerate(file_batches):
        print(f"  Batch {i+1}/{len(file_batches)}: migrating {len(file_batch)} files...")

        files_content = []
        for f in file_batch:
            rel = f.relative_to(source_root)
            content = read_file_safe(f)
            files_content.append(f"=== {rel} ===\n{content}")

        prompt = f"""## Project context (for reference)
{context_summary}

---

## Files to migrate

Migrate each of the following files from Convex to Supabase.
Import the Supabase client from `../../supabase/config` (adjust relative path as needed).
Import types from `../../supabase/types` (adjust relative path as needed).

{chr(10).join(files_content)}"""

        response = call_cursor_api(SYSTEM_PROMPT, prompt, api_key)
        changes = parse_file_blocks(response)
        all_changes.extend(changes)
        print(f"    â†’ {len(changes)} file changes generated")

        time.sleep(REQUEST_DELAY_SECONDS)

    return all_changes


def step_apply_changes(
    source_root: Path,
    target_root: Path,
    all_changes: list[dict],
    dry_run: bool,
) -> dict:
    """Copy source â†’ target, remove convex/, apply AI changes."""
    stats = {"copied": 0, "written": 0, "deleted": 0, "skipped": 0}

    if dry_run:
        print("  [DRY RUN] Skipping file writes")
        stats["written"] = len([c for c in all_changes if c["action"] == "write"])
        stats["deleted"] = len([c for c in all_changes if c["action"] == "delete"])
        return stats

    # 1. Copy entire source â†’ target (excluding convex/ and node_modules)
    print("  Copying source â†’ target (excluding convex/)...")
    for src_file in iter_source_files(source_root):
        rel = src_file.relative_to(source_root)
        # Skip the convex/ directory entirely
        if rel.parts and rel.parts[0] == "convex":
            continue
        dest = target_root / rel
        dest.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(src_file, dest)
        stats["copied"] += 1

    # 2. Apply AI-generated changes
    print(f"  Applying {len(all_changes)} AI-generated changes...")
    for change in all_changes:
        dest = target_root / change["path"]
        if change["action"] == "write":
            dest.parent.mkdir(parents=True, exist_ok=True)
            dest.write_text(change["content"], encoding="utf-8")
            stats["written"] += 1
        elif change["action"] == "delete":
            if dest.exists():
                dest.unlink()
                stats["deleted"] += 1
            else:
                stats["skipped"] += 1

    return stats


def build_context_summary(source_root: Path) -> str:
    """Build a compact project context string for the AI."""
    parts = []

    priority_files = [
        "package.json", "app.json", "tsconfig.json",
        "App.tsx", "app/_layout.tsx", "app/index.tsx",
    ]
    for name in priority_files:
        p = source_root / name
        if p.exists():
            content = read_file_safe(p)
            # Truncate large files
            if len(content) > 2000:
                content = content[:2000] + "\n...[truncated]"
            parts.append(f"=== {name} ===\n{content}")

    summary = "\n\n".join(parts)
    # Hard cap at 4000 chars for context
    return summary[:4000] if len(summary) > 4000 else summary


def write_report(
    source_root: Path,
    all_changes: list[dict],
    stats: dict,
    dry_run: bool,
) -> None:
    """Write a markdown migration report."""
    written = [c for c in all_changes if c["action"] == "write"]
    deleted = [c for c in all_changes if c["action"] == "delete"]

    lines = [
        "# Migration Report: Convex â†’ Supabase",
        "",
        f"**Source:** `{source_root}`",
        f"**Dry run:** `{dry_run}`",
        "",
        "## Summary",
        "",
        f"| Action | Count |",
        f"|--------|-------|",
        f"| Files copied (unchanged) | {stats.get('copied', 0)} |",
        f"| Files written/created by AI | {stats.get('written', 0)} |",
        f"| Files deleted | {stats.get('deleted', 0)} |",
        "",
        "## Files Created / Modified",
        "",
    ]
    for c in written:
        lines.append(f"- `{c['path']}`")

    if deleted:
        lines += ["", "## Files Deleted", ""]
        for c in deleted:
            lines.append(f"- `{c['path']}`")

    lines += [
        "",
        "## Next Steps",
        "",
        "1. Create a Supabase project at https://supabase.com",
        "2. Run `supabase/migrations/001_initial.sql` in the SQL Editor",
        "3. Copy `.env.example` â†’ `.env` and fill in your Supabase credentials",
        "4. Run `npm install` then `npx expo start`",
        "5. Review RLS policies in the migration SQL â€” tighten as needed",
    ]

    report_path = Path("migration_report.md")
    report_path.write_text("\n".join(lines), encoding="utf-8")
    print(f"\nğŸ“„ Report written to {report_path}")


# â”€â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="Convex â†’ Supabase migration agent")
    parser.add_argument("--source", required=True, help="Path to cloned source repo")
    parser.add_argument("--target", required=True, help="Path to cloned target repo")
    parser.add_argument(
        "--dry-run",
        default="false",
        choices=["true", "false"],
        help="If true, analyze only and don't write files",
    )
    args = parser.parse_args()

    dry_run = args.dry_run.lower() == "true"
    source_root = Path(args.source).resolve()
    target_root = Path(args.target).resolve()

    api_key = os.environ.get("CURSOR_API_KEY", "")
    if not api_key:
        print("âŒ CURSOR_API_KEY environment variable is not set", file=sys.stderr)
        sys.exit(1)

    print("\nğŸ¤– Convex â†’ Supabase Migration Agent")
    print("=" * 50)
    print(f"   Source: {source_root}")
    print(f"   Target: {target_root}")
    print(f"   Dry run: {dry_run}")
    print("=" * 50)

    # â”€â”€ Step 1: Analyze â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ” Step 1: Analyzing codebase...")
    analysis = step_analyze(source_root)

    if not analysis["convex_files"] and not analysis["convex_using"]:
        print("âš ï¸  No Convex usage detected. Nothing to migrate.")
        sys.exit(0)

    # â”€â”€ Step 2: Build context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“‹ Step 2: Building project context...")
    context_summary = build_context_summary(source_root)

    # â”€â”€ Step 3: Generate Supabase schema & config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“Š Step 3: Generating Supabase schema, types, and config...")
    schema_changes = step_generate_schema(source_root, api_key)
    time.sleep(REQUEST_DELAY_SECONDS)

    # â”€â”€ Step 4: Migrate app files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ”„ Step 4: Migrating {len(analysis['convex_using'])} files that use Convex...")
    app_changes = step_migrate_files(
        source_root,
        analysis["convex_using"],
        context_summary,
        api_key,
    )

    all_changes = schema_changes + app_changes
    print(f"\nâœ… Total AI-generated changes: {len(all_changes)}")

    # â”€â”€ Step 5: Apply changes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nâœï¸  Step 5: Applying changes to target repo...")
    stats = step_apply_changes(source_root, target_root, all_changes, dry_run)
    print(f"   Copied: {stats['copied']}  Written: {stats['written']}  Deleted: {stats['deleted']}")

    # â”€â”€ Step 6: Write report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“„ Step 6: Writing migration report...")
    write_report(source_root, all_changes, stats, dry_run)

    print("\nğŸ‰ Agent finished successfully!")
    if dry_run:
        print("   (Dry run â€” no files were written to the target repo)")


if __name__ == "__main__":
    main()